{
  "name": "Chat with Transcription - Option B",
  "nodes": [
    {
      "parameters": {
        "options": {}
      },
      "type": "@n8n/n8n-nodes-langchain.chatTrigger",
      "typeVersion": 1.1,
      "position": [
        -520,
        -80
      ],
      "id": "540b1a71-4efc-4bf5-9a3c-00c38e4f937d",
      "name": "When chat message received",
      "webhookId": "3f9caa96-1d4a-44f7-ac20-c8fda61c4da9"
    },
    {
      "parameters": {
        "promptType": "define",
        "text": "={{ $json.chat.chatInput }}",
        "hasOutputParser": true,
        "options": {
          "systemMessage": "=Eres un asistente inteligente cuyo propósito es ayudar al usuario proporcionándole información precisa y relevante. Para lograr esto, puedes interpretar la intención del usuario y buscar contenido semánticamente relacionado en una base de datos vectorial alojada en Qdrant.\n\nCuando recibas una consulta del usuario, debes usar la herramienta qdrantSearch para buscar información relevante en la base de datos. Solo después de obtener resultados, genera una respuesta basada en los documentos encontrados.\n\nCuando el usuario realice una consulta o formule una pregunta, deberás:\n1. Comprender la intención principal del mensaje.\n2. Generar una representación vectorial del contenido (embedding).\n3. Realizar una búsqueda en Qdrant utilizando ese vector para encontrar información similar.\n4. Analizar los resultados obtenidos y sintetizar una respuesta clara, útil y adaptada al contexto del usuario.\n\nTu objetivo es actuar como un asistente proactivo, preciso y orientado a la utilidad, capaz de conectar la intención del usuario con conocimiento previamente indexado en la base de datos.\n\nSi no encuentras información relevante en la base de datos, responde de forma transparente e intenta guiar al usuario hacia una reformulación o consulta adicional.\n\nMantén siempre un tono profesional, claro y empático."
        }
      },
      "type": "@n8n/n8n-nodes-langchain.agent",
      "typeVersion": 1.8,
      "position": [
        60,
        -80
      ],
      "id": "1fcc60cf-2f4b-4e47-82a8-84fb3b4eb9e2",
      "name": "AI Agent"
    },
    {
      "parameters": {
        "modelName": "models/gemini-2.5-pro-preview-03-25",
        "options": {}
      },
      "type": "@n8n/n8n-nodes-langchain.lmChatGoogleGemini",
      "typeVersion": 1,
      "position": [
        -60,
        120
      ],
      "id": "002139f0-c505-42a4-8e1e-9c55ea91337e",
      "name": "Google Gemini Chat Model",
      "credentials": {
        "googlePalmApi": {
          "id": "fyUtFUvJF3bGUg4z",
          "name": "Google Gemini(PaLM) Api account"
        }
      }
    },
    {
      "parameters": {
        "assignments": {
          "assignments": [
            {
              "id": "5c182502-60e6-4198-8574-bf2dc5ca0895",
              "name": "chat",
              "value": "={{ $json }}",
              "type": "object"
            },
            {
              "id": "64d0ba93-689e-4920-a2ce-545fdb99d8e9",
              "name": "vector_dadtabase_name",
              "value": "transcription_embeddings_a",
              "type": "string"
            }
          ]
        },
        "options": {}
      },
      "type": "n8n-nodes-base.set",
      "typeVersion": 3.4,
      "position": [
        -300,
        -80
      ],
      "id": "f6256fe1-6982-44ae-bcaf-26c5ee11690f",
      "name": "Edit Fields"
    },
    {
      "parameters": {
        "sessionIdType": "customKey",
        "sessionKey": "={{ $json.chat.sessionId }}",
        "contextWindowLength": 10
      },
      "type": "@n8n/n8n-nodes-langchain.memoryBufferWindow",
      "typeVersion": 1.3,
      "position": [
        100,
        120
      ],
      "id": "687e1bff-8e88-4547-aafc-d2f2cba083ec",
      "name": "Simple Memory"
    },
    {
      "parameters": {
        "mode": "retrieve-as-tool",
        "toolName": "={{ $json.vector_dadtabase_name }}",
        "toolDescription": "Esta tool se usa para buscar las transcripciones de audio. Cuando se refieren a transcripciones de audio, la conversación, la reunión, se refieren a los registros almacenados en la base de datos.",
        "qdrantCollection": {
          "__rl": true,
          "value": "={{ $json.vector_dadtabase_name }}",
          "mode": "id"
        },
        "options": {}
      },
      "type": "@n8n/n8n-nodes-langchain.vectorStoreQdrant",
      "typeVersion": 1.1,
      "position": [
        240,
        120
      ],
      "id": "886c9647-28ec-45eb-a3fd-3411524576c5",
      "name": "Qdrant Vector Store",
      "credentials": {
        "qdrantApi": {
          "id": "ZWm1zOTiZzpOmpdB",
          "name": "QdrantApi account"
        }
      }
    },
    {
      "parameters": {
        "options": {}
      },
      "type": "@n8n/n8n-nodes-langchain.embeddingsHuggingFaceInference",
      "typeVersion": 1,
      "position": [
        240,
        300
      ],
      "id": "55e4af47-e110-435f-aa87-0eda0dacbf54",
      "name": "Embeddings HuggingFace Inference",
      "credentials": {
        "huggingFaceApi": {
          "id": "4JqrfLS96mF0rpms",
          "name": "HuggingFaceApi account"
        }
      }
    }
  ],
  "pinData": {},
  "connections": {
    "When chat message received": {
      "main": [
        [
          {
            "node": "Edit Fields",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Google Gemini Chat Model": {
      "ai_languageModel": [
        [
          {
            "node": "AI Agent",
            "type": "ai_languageModel",
            "index": 0
          }
        ]
      ]
    },
    "Edit Fields": {
      "main": [
        [
          {
            "node": "AI Agent",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Simple Memory": {
      "ai_memory": [
        [
          {
            "node": "AI Agent",
            "type": "ai_memory",
            "index": 0
          }
        ]
      ]
    },
    "Qdrant Vector Store": {
      "ai_tool": [
        [
          {
            "node": "AI Agent",
            "type": "ai_tool",
            "index": 0
          }
        ]
      ]
    },
    "Embeddings HuggingFace Inference": {
      "ai_embedding": [
        [
          {
            "node": "Qdrant Vector Store",
            "type": "ai_embedding",
            "index": 0
          }
        ]
      ]
    }
  },
  "active": false,
  "settings": {
    "executionOrder": "v1"
  },
  "versionId": "29dce4b7-460c-42d0-8bbf-afec0a121ce7",
  "meta": {
    "templateCredsSetupCompleted": true,
    "instanceId": "be6c6d7ff7c15c8469c795932a0a6b3b9d114f5a447f9d3fb2f8180e44bcf430"
  },
  "id": "3zttqFlLx8O15B3b",
  "tags": []
}